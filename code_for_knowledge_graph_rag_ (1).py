# -*- coding: utf-8 -*-
"""Code_for_Knowledge_Graph_RAG_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjSin6QsMk3wOpb_nAoaSrnXMSzCd-eY
"""

!pip install httpx==0.23.0

"""
### Step 1: Install Required Libraries

First, ensure you have the necessary libraries installed. In Google Colab, you can run shell commands by prefixing them with `!`."""

# Install RDFLib for working with RDF data
!pip install rdflib

# Install OpenAI for using a language model (LLM)
!pip install openai

"""- **RDFLib**: A Python library for working with RDF (Resource Description Framework) data, which is used to create and manipulate knowledge graphs.

### Step 2:  **Import Libraries**

Next, import the necessary libraries in your Python code.
"""

from rdflib import Graph, URIRef, Literal
import openai

"""- **Graph**: Represents an RDF graph.

- **URIRef**: Represents a URI reference.

- **Literal**: Represents a literal value in RDF.

- **openai**: The library to interact with OpenAI's language models.

## What is Knowledge Graph?
A Knowledge graph is a way of storing data that resulted from an information extraction task. Many basic implementations of knowledge graphs make use of a concept we call triple, that is a set of three items`(a subject, a predicate and an object)`that we can use to store information about something.

### Step 3: Create a Knowledge Graph
Let's create a simple knowledge graph using RDFLib.
"""

# Create a new RDF graph
g = Graph()

# Add a triple to the graph
g.add((URIRef("http://example.com/rag"), URIRef("http://example.com/is"), Literal("Retrieval-Augmented Generation")))

# Serialize the graph to a string in Turtle format
print(g.serialize(format="turtle"))

"""A triple is a fundamental building block of a Resource Description Framework (RDF) graph. In this case:

*   `Subject` (http://example.com/rag): Identifies the entity we are describing (e.g., "RAG").
*  `Predicate `(http://example.com/is): Specifies the relationship or property (e.g., "is").
*  `Object `("Retrieval-Augmented Generation"): Provides the value or description (e.g., the definition of "RAG").

This structure lets you represent knowledge in a structured and machine-readable format.

### Step 4: Use a Language Model (LLM)

Now, let's integrate a language model to perform Retrieval-Augmented Generation (RAG). You need to set your OpenAI API key to use the language model.
"""

# Set your OpenAI API key
openai.api_key = "YOUR-API-KEY"

def generate_response(prompt):
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=100
    )
    return response.choices[0].message.content.strip()

# Example usage
prompt = "Explain Retrieval-Augmented Generation."
response = generate_response(prompt)
print("LLM Response:", response)

"""- **generate_response**: A function to generate a response from the language model using a given prompt.

### Explanation and Links

1. **RDFLib**:

   - [RDFLib Documentation](https://rdflib.readthedocs.io/en/stable/)
   
   - RDFLib is used to create and manipulate RDF graphs, which are useful for representing knowledge in a structured form.
   
2. **OpenAI**:

   - [OpenAI API Documentation](https://beta.openai.com/docs/)
   
   - OpenAI provides powerful language models that can be used for various natural language processing tasks, including RAG.
   
3. **Retrieval-Augmented Generation (RAG)**:

   - RAG is a technique that combines retrieval of relevant information with generation of text using a language model. It is useful for tasks that require both factual accuracy and natural language generation.
"""